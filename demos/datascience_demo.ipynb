{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "#importsimport numpy as np\n",
    "\n",
    "#ai\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import RMSprop, SGD, Adam, Nadam\n",
    "from sklearn.datasets import make_blobs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "#wandb\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "\n",
    "from astroLuSt.datascience import (\n",
    "    clustering as aldacl,\n",
    "    dtw as aldadt,\n",
    "    layers as aldala,\n",
    "    metrics as aldame,\n",
    "    mle as aldamle,\n",
    "    totables as aldato,\n",
    ")\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WandB_parallel_sweep\n",
    "\n",
    "This demonstration of the usage for the WandB_parallel_sweep class is based on the tutorial by Weights and Biases.\n",
    "The original tutorial and colab notebook can be found here:\n",
    "- [https://wandb.ai/site/articles/hyperparameter-tuning-as-easy-as-1-2-3](https://wandb.ai/site/articles/hyperparameter-tuning-as-easy-as-1-2-3)\n",
    "- [https://colab.research.google.com/drive/1gKixa6hNUB8qrn1CfHirOfTEQm0qLCSS#scrollTo=aIhxl7glaJ5k](https://colab.research.google.com/drive/1gKixa6hNUB8qrn1CfHirOfTEQm0qLCSS#scrollTo=aIhxl7glaJ5k)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder:\n",
    "    def __init__(self, input_shape, original_dim, intermediate_dim, latent_dim):\n",
    "        self.input_shape = input_shape\n",
    "        self.original_dim = original_dim\n",
    "        self.intermediate_dim = intermediate_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def build_model(self):\n",
    "        # instantiate VAE model\n",
    "        self.build_encoder()\n",
    "        self.build_decoder()\n",
    "\n",
    "        self.outputs = self.decoder(self.encoder(self.inputs)[2])\n",
    "\n",
    "        self.vae = keras.models.Model(self.inputs, self.outputs, name='vae_mlp')\n",
    "        self.add_loss()\n",
    "\n",
    "        return self.vae\n",
    "\n",
    "    def sampling(self, args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        # by default, random_normal has mean = 0 and std = 1.0\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    def build_encoder(self):\n",
    "        self.inputs = keras.layers.Input(shape=self.input_shape, name='encoder_input')\n",
    "        x = keras.layers.Dense(self.intermediate_dim, activation='relu')(self.inputs)\n",
    "        self.z_mean = keras.layers.Dense(self.latent_dim, name='z_mean')(x)\n",
    "        self.z_log_var = keras.layers.Dense(self.latent_dim, name='z_log_var')(x)\n",
    "\n",
    "        self.z = keras.layers.Lambda(self.sampling, output_shape=(self.latent_dim,), name='z')([self.z_mean, self.z_log_var])\n",
    "\n",
    "        # instantiate encoder model\n",
    "        self.encoder = keras.models.Model(self.inputs, [self.z_mean, self.z_log_var, self.z], name='encoder')\n",
    "\n",
    "\n",
    "    def build_decoder(self):\n",
    "        latent_inputs = keras.layers.Input(shape=(self.latent_dim,), name='z_sampling')\n",
    "        x = keras.layers.Dense(self.intermediate_dim, activation='relu')(latent_inputs)\n",
    "        outputs = keras.layers.Dense(self.original_dim, activation='sigmoid')(x)\n",
    "\n",
    "        # instantiate decoder model\n",
    "        self.decoder = keras.models.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    def add_loss(self):\n",
    "        # VAE loss = mse_loss or xent_loss + kl_loss\n",
    "        reconstruction_loss = keras.losses.mse(self.inputs, self.outputs)\n",
    "        reconstruction_loss *= self.original_dim\n",
    "\n",
    "        kl_loss = 1 + self.z_log_var - K.square(self.z_mean) - K.exp(self.z_log_var)\n",
    "        kl_loss = K.sum(kl_loss, axis=-1)\n",
    "        kl_loss *= -0.5\n",
    "\n",
    "        vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "        self.vae.add_loss(vae_loss)\n",
    "\n",
    "\n",
    "\n",
    "        keras.backend.clear_session()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReconstructionLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        super(ReconstructionLogger, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, logs, epoch):\n",
    "        sample_images = x_test[:self.batch_size]\n",
    "        \n",
    "        images = []\n",
    "        reconstructions = []\n",
    "        \n",
    "        for i in range(32):\n",
    "            reconstruction = self.model.predict(sample_images[i].reshape((1,)+sample_images[i].shape))\n",
    "\n",
    "            images.append(sample_images[i].reshape(28,28))\n",
    "            reconstructions.append(reconstruction.reshape(28,28))\n",
    "\n",
    "        wandb.log({\"images\": [wandb.Image(image)\n",
    "                            for image in images]})\n",
    "        wandb.log({\"reconstructions\": [wandb.Image(reconstruction)\n",
    "                            for reconstruction in reconstructions]})\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop to be called by each agent during the sweep\n",
    "\n",
    "The training loop usually contains\n",
    "- run initialization\n",
    "- model definintion\n",
    "- model building\n",
    "- model compiling\n",
    "- model fitting\n",
    "- some extra logging if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "\n",
    "    config_defaults = {\n",
    "       'epochs':5,\n",
    "       'batch_size':64,\n",
    "       'learning_rate':1e-3,\n",
    "    }\n",
    "\n",
    "    run = wandb.init(\n",
    "        # Set the project where this run will be logged\n",
    "        project=\"sweeptesting\",\n",
    "        config=config_defaults,\n",
    "    )\n",
    "\n",
    "    config = wandb.config\n",
    "\n",
    "    #callbacks\n",
    "    callbacks = (\n",
    "        WandbCallback(save_model=False),\n",
    "        ReconstructionLogger(config.batch_size),\n",
    "    )\n",
    "    \n",
    "    opt = Adam(lr=config.learning_rate, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "\n",
    "    K.clear_session()\n",
    "    vae = VariationalAutoencoder(input_shape=(784), \n",
    "                                original_dim=(784), \n",
    "                                intermediate_dim=512,\n",
    "                                latent_dim=2)\n",
    "    model = vae.build_model()\n",
    "    model.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "    hist = model.fit(x_train, \n",
    "                x_train, \n",
    "                epochs=config.epochs, \n",
    "                batch_size=config.batch_size,\n",
    "                callbacks=callbacks)\n",
    "    \n",
    "    run.finish()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/lukas/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: uqok8a6z\n",
      "Sweep URL: https://wandb.ai/lust/sweeptesting/sweeps/uqok8a6z\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wandb.login()\n",
    "\n",
    "\n",
    "# Configure the sweep â€“ specify the parameters to search through, the search strategy, the optimization metric et all.\n",
    "sweep_config = {\n",
    "    'method':'grid', #grid, random\n",
    "    'metric':{\n",
    "        'name'  : 'accuracy',\n",
    "        'goal'  : 'maximize'   \n",
    "    },\n",
    "    'run_cap':4,\n",
    "    'parameters':{\n",
    "        'epochs':{\n",
    "            'values':[2]\n",
    "        },\n",
    "        'batch_size':{\n",
    "            'values':[256, 128]\n",
    "        },\n",
    "        'learning_rate':{\n",
    "            'values':[1e-2, 1e-3]\n",
    "        },\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, entity=None, project=\"sweeptesting\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (60000, 784)\n",
      "X_test:  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "#MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "original_dim = image_size * image_size\n",
    "x_train = np.reshape(x_train, [-1, original_dim])\n",
    "x_test = np.reshape(x_test, [-1, original_dim])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "## Just dataset info\n",
    "print(\"X_train: \", x_train.shape)\n",
    "print(\"X_test: \", x_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating and running a parallelized sweeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB_parallel_sweep(\n",
      "    sweep_id='uqok8a6z', function=<function train at 0x7af00bf8c160>,\n",
      "    n_jobs=4, n_agents=4,\n",
      "    wandb_mode='online',\n",
      "    verbose=3,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "PS = aldawa.WandB_parallel_sweep(\n",
    "   sweep_id, train, n_jobs=4, n_agents=-1, wandb_mode='online', verbose=3,\n",
    ")\n",
    "\n",
    "#estimate upper bound of required agents and adopting it in PS\n",
    "n_comb = PS.get_upper_bound_agents(sweep_config)\n",
    "PS.n_agents = n_comb\n",
    "\n",
    "print(PS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO(sweep_parallel()): Using n_jobs=4 jobs and n_agents=4 agents to run sweep.\n",
      "\n",
      "######################################################################\n",
      "INFO: Started sweep_parallel at 2024-11-04T12:14:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "2024-11-04 13:14:21.007661: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-04 13:14:21.007661: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-04 13:14:21.007681: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-04 13:14:21.012426: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "INFO: Started sweep_one, agent 2 at 2024-11-04T12:14:22\n",
      "INFO(sweep_one): Sweeping with agent 2/4\n",
      "\n",
      "######################################################################\n",
      "INFO: Started sweep_one, agent 4 at 2024-11-04T12:14:22\n",
      "INFO(sweep_one): Sweeping with agent 4/4\n",
      "\n",
      "######################################################################\n",
      "INFO: Started sweep_one, agent 1 at 2024-11-04T12:14:22\n",
      "INFO(sweep_one): Sweeping with agent 1/4\n",
      "\n",
      "######################################################################\n",
      "INFO: Started sweep_one, agent 3 at 2024-11-04T12:14:22\n",
      "INFO(sweep_one): Sweeping with agent 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run e524e8z4 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n",
      "    wandb.sdk.wandb_setup._setup(_reset=True)\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 327, in _setup\n",
      "    teardown()\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 409, in teardown\n",
      "    setup_instance._teardown(exit_code=exit_code)\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 280, in _teardown\n",
      "    internal_exit_code = self._connection.teardown(exit_code or 0)\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py\", line 197, in teardown\n",
      "    raise WandbServiceNotOwnedError(\n",
      "wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n",
      "\n",
      "wandb: ERROR Run e524e8z4 errored:\n",
      "wandb: ERROR Traceback (most recent call last):\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n",
      "wandb: ERROR     wandb.sdk.wandb_setup._setup(_reset=True)\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 327, in _setup\n",
      "wandb: ERROR     teardown()\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 409, in teardown\n",
      "wandb: ERROR     setup_instance._teardown(exit_code=exit_code)\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 280, in _teardown\n",
      "wandb: ERROR     internal_exit_code = self._connection.teardown(exit_code or 0)\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py\", line 197, in teardown\n",
      "wandb: ERROR     raise WandbServiceNotOwnedError(\n",
      "wandb: ERROR wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n",
      "wandb: ERROR \n",
      "Run 5k26cb5k errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n",
      "    wandb.sdk.wandb_setup._setup(_reset=True)\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 327, in _setup\n",
      "    teardown()\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 409, in teardown\n",
      "    setup_instance._teardown(exit_code=exit_code)\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 280, in _teardown\n",
      "    internal_exit_code = self._connection.teardown(exit_code or 0)\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py\", line 197, in teardown\n",
      "    raise WandbServiceNotOwnedError(\n",
      "wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n",
      "\n",
      "wandb: ERROR Run 5k26cb5k errored:\n",
      "wandb: ERROR Traceback (most recent call last):\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n",
      "wandb: ERROR     wandb.sdk.wandb_setup._setup(_reset=True)\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 327, in _setup\n",
      "wandb: ERROR     teardown()\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 409, in teardown\n",
      "wandb: ERROR     setup_instance._teardown(exit_code=exit_code)\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 280, in _teardown\n",
      "wandb: ERROR     internal_exit_code = self._connection.teardown(exit_code or 0)\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py\", line 197, in teardown\n",
      "wandb: ERROR     raise WandbServiceNotOwnedError(\n",
      "wandb: ERROR wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n",
      "wandb: ERROR \n",
      "Run p0d4ikrb errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n",
      "    wandb.sdk.wandb_setup._setup(_reset=True)\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 327, in _setup\n",
      "    teardown()\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 409, in teardown\n",
      "    setup_instance._teardown(exit_code=exit_code)\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 280, in _teardown\n",
      "    internal_exit_code = self._connection.teardown(exit_code or 0)\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py\", line 197, in teardown\n",
      "    raise WandbServiceNotOwnedError(\n",
      "wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n",
      "\n",
      "wandb: ERROR Run p0d4ikrb errored:\n",
      "wandb: ERROR Traceback (most recent call last):\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n",
      "wandb: ERROR     wandb.sdk.wandb_setup._setup(_reset=True)\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 327, in _setup\n",
      "wandb: ERROR     teardown()\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 409, in teardown\n",
      "wandb: ERROR     setup_instance._teardown(exit_code=exit_code)\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 280, in _teardown\n",
      "wandb: ERROR     internal_exit_code = self._connection.teardown(exit_code or 0)\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py\", line 197, in teardown\n",
      "wandb: ERROR     raise WandbServiceNotOwnedError(\n",
      "wandb: ERROR wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n",
      "wandb: ERROR \n",
      "Run jfmkin96 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n",
      "    wandb.sdk.wandb_setup._setup(_reset=True)\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 327, in _setup\n",
      "    teardown()\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 409, in teardown\n",
      "    setup_instance._teardown(exit_code=exit_code)\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 280, in _teardown\n",
      "    internal_exit_code = self._connection.teardown(exit_code or 0)\n",
      "  File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py\", line 197, in teardown\n",
      "    raise WandbServiceNotOwnedError(\n",
      "wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n",
      "\n",
      "wandb: ERROR Run jfmkin96 errored:\n",
      "wandb: ERROR Traceback (most recent call last):\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n",
      "wandb: ERROR     wandb.sdk.wandb_setup._setup(_reset=True)\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 327, in _setup\n",
      "wandb: ERROR     teardown()\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 409, in teardown\n",
      "wandb: ERROR     setup_instance._teardown(exit_code=exit_code)\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py\", line 280, in _teardown\n",
      "wandb: ERROR     internal_exit_code = self._connection.teardown(exit_code or 0)\n",
      "wandb: ERROR   File \"/home/lukas/venvs/astroLuSt/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py\", line 197, in teardown\n",
      "wandb: ERROR     raise WandbServiceNotOwnedError(\n",
      "wandb: ERROR wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n",
      "wandb: ERROR \n",
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Sweep Agent: Waiting for job.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mPS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msweep_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/astroLuSt/demos/../astroLuSt/datascience/wandb_utils.py:357\u001b[0m, in \u001b[0;36mWandB_parallel_sweep.sweep_parallel\u001b[0;34m(self, sweep_id, function, n_jobs, n_agents, verbose)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mET\u001b[38;5;241m.\u001b[39mcheckpoint_start(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msweep_parallel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m#execute paralellized hyperparameter sweep\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msweep_one\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43msweep_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msweep_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_agents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_agents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_agents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mET\u001b[38;5;241m.\u001b[39mcheckpoint_end(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msweep_parallel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/astroLuSt/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/astroLuSt/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/astroLuSt/lib/python3.10/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PS.sweep_parallel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Task               Start                  End         Duration  \\\n",
      "0  sweep_parallel 2023-05-03 19:03:23  2023-05-03T19:04:36  0 days 00:01:13   \n",
      "\n",
      "  Comment_Start Comment_End  \n",
      "0                            \n"
     ]
    }
   ],
   "source": [
    "print(PS.ET.df_protocoll)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-, Validation-, Test-Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(alap)\n",
    "\n",
    "#generate pseudo dataset\n",
    "X1 =  np.linspace((1,1),(100,100), 100)\n",
    "X2 =  np.ones((X1.shape[0],5))\n",
    "y = np.random.randint(0,1, size=(X1.shape[0],1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_train.shape=(60, 2)\n",
      "X1_val.shape=(30, 2)\n",
      "X1_test.shape=(10, 2)\n",
      "X2_train.shape=(60, 5)\n",
      "X2_val.shape=(30, 5)\n",
      "X2_test.shape=(10, 5)\n",
      "y_train.shape=(60, 1)\n",
      "y_val.shape=(30, 1)\n",
      "y_test.shape=(10, 1)\n",
      "[[81. 81.]\n",
      " [85. 85.]\n",
      " [34. 34.]]\n"
     ]
    }
   ],
   "source": [
    "#split with shuffling and random state\n",
    "X1_train, X1_val, X1_test, \\\n",
    "    X2_train, X2_val, X2_test,\\\n",
    "    y_train, y_val, y_test = \\\n",
    "    alap.data_split(\n",
    "        arrays=[X1, X2, y],\n",
    "        split_fractions=[0.6,0.3],\n",
    "        shuffle=True,\n",
    "        random_state=1\n",
    "    )\n",
    "\n",
    "print(f'{X1_train.shape=}')\n",
    "print(f'{X1_val.shape=}')\n",
    "print(f'{X1_test.shape=}')\n",
    "print(f'{X2_train.shape=}')\n",
    "print(f'{X2_val.shape=}')\n",
    "print(f'{X2_test.shape=}')\n",
    "print(f'{y_train.shape=}')\n",
    "print(f'{y_val.shape=}')\n",
    "print(f'{y_test.shape=}')\n",
    "\n",
    "print(X1_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_train.shape=(60, 2)\n",
      "X1_val.shape=(10, 2)\n",
      "X1_test.shape=(30, 2)\n",
      "X2_train.shape=(60, 5)\n",
      "X2_val.shape=(10, 5)\n",
      "X2_test.shape=(30, 5)\n",
      "y_train.shape=(60, 1)\n",
      "y_val.shape=(10, 1)\n",
      "y_test.shape=(30, 1)\n",
      "[[1. 1.]\n",
      " [2. 2.]\n",
      " [3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "#split without shuffling\n",
    "X1_train, X1_val, X1_test, \\\n",
    "    X2_train, X2_val, X2_test,\\\n",
    "    y_train, y_val, y_test = \\\n",
    "    alap.data_split(\n",
    "        arrays=[X1, X2, y],\n",
    "        split_fractions=[0.6,0.1],\n",
    "        shuffle=False,\n",
    "        random_state=1\n",
    "    )\n",
    "\n",
    "print(f'{X1_train.shape=}')\n",
    "print(f'{X1_val.shape=}')\n",
    "print(f'{X1_test.shape=}')\n",
    "print(f'{X2_train.shape=}')\n",
    "print(f'{X2_val.shape=}')\n",
    "print(f'{X2_test.shape=}')\n",
    "print(f'{y_train.shape=}')\n",
    "print(f'{y_val.shape=}')\n",
    "print(f'{y_test.shape=}')\n",
    "\n",
    "print(X1_train[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astroLuSt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
